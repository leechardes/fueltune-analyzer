==================
Arquitetura do Sistema
==================

Esta se√ß√£o descreve a arquitetura completa do FuelTune Analyzer, incluindo padr√µes de design, 
organiza√ß√£o de c√≥digo, fluxo de dados e decis√µes arquiteturais. √â essencial para desenvolvedores 
que queiram contribuir ou estender o sistema.

.. note::
   **P√∫blico-alvo**: Desenvolvedores, arquitetos de software, contribuidores
   
   **Pr√©-requisitos**: Conhecimento em Python, Streamlit, pandas, padr√µes de design

üèóÔ∏è Vis√£o Geral da Arquitetura
=============================

O FuelTune Analyzer segue uma arquitetura em camadas com separa√ß√£o clara de responsabilidades, 
baseada nos princ√≠pios de Clean Architecture e Domain-Driven Design.

.. mermaid::

   graph TB
       subgraph "Presentation Layer"
           UI[Streamlit UI]
           API[REST API]
           CLI[Command Line]
       end
       
       subgraph "Application Layer"
           APP[Application Services]
           WORK[Workflow Manager]
           CACHE[Cache Manager]
       end
       
       subgraph "Domain Layer"
           MODELS[Domain Models]
           SERVICES[Domain Services]
           ANALYSIS[Analysis Engine]
       end
       
       subgraph "Infrastructure Layer"
           DB[Database]
           FILES[File System]
           EXTERN[External APIs]
       end
       
       UI --> APP
       API --> APP
       CLI --> APP
       APP --> SERVICES
       WORK --> SERVICES
       SERVICES --> MODELS
       ANALYSIS --> MODELS
       SERVICES --> DB
       SERVICES --> FILES
       APP --> EXTERN

## Princ√≠pios Arquiteturais

**1. Separation of Concerns**
   Cada m√≥dulo tem uma responsabilidade espec√≠fica e bem definida

**2. Dependency Inversion**
   Depend√™ncias apontam para abstra√ß√µes, n√£o implementa√ß√µes concretas

**3. Single Responsibility**
   Classes e m√≥dulos t√™m uma √∫nica raz√£o para mudar

**4. Open/Closed Principle**
   Extens√≠vel para novos recursos, fechado para modifica√ß√µes

**5. Interface Segregation**
   Interfaces pequenas e espec√≠ficas para cada contexto

üì¶ Organiza√ß√£o de M√≥dulos
=========================

Estrutura de Diret√≥rios
-----------------------

.. code-block:: text

   src/
   ‚îú‚îÄ‚îÄ data/                    # üìä Camada de Dados
   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
   ‚îÇ   ‚îú‚îÄ‚îÄ models.py           # Modelos de dom√≠nio
   ‚îÇ   ‚îú‚îÄ‚îÄ csv_parser.py       # Parser de arquivos
   ‚îÇ   ‚îú‚îÄ‚îÄ validators.py       # Valida√ß√£o de dados
   ‚îÇ   ‚îú‚îÄ‚îÄ normalizer.py       # Normaliza√ß√£o
   ‚îÇ   ‚îú‚îÄ‚îÄ cache.py           # Sistema de cache
   ‚îÇ   ‚îú‚îÄ‚îÄ database.py        # Persist√™ncia
   ‚îÇ   ‚îî‚îÄ‚îÄ quality.py         # Qualidade de dados
   ‚îÇ
   ‚îú‚îÄ‚îÄ analysis/               # üî¨ Camada de An√°lise
   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
   ‚îÇ   ‚îú‚îÄ‚îÄ analysis.py        # Factory de analisadores
   ‚îÇ   ‚îú‚îÄ‚îÄ performance.py     # An√°lise de performance
   ‚îÇ   ‚îú‚îÄ‚îÄ statistics.py      # An√°lises estat√≠sticas
   ‚îÇ   ‚îú‚îÄ‚îÄ correlation.py     # An√°lise de correla√ß√£o
   ‚îÇ   ‚îú‚îÄ‚îÄ anomaly.py         # Detec√ß√£o de anomalias
   ‚îÇ   ‚îú‚îÄ‚îÄ predictive.py      # An√°lises preditivas
   ‚îÇ   ‚îú‚îÄ‚îÄ time_series.py     # An√°lises temporais
   ‚îÇ   ‚îú‚îÄ‚îÄ fuel_efficiency.py # Efici√™ncia combust√≠vel
   ‚îÇ   ‚îú‚îÄ‚îÄ dynamics.py        # An√°lises din√¢micas
   ‚îÇ   ‚îî‚îÄ‚îÄ reports.py         # Gera√ß√£o de relat√≥rios
   ‚îÇ
   ‚îú‚îÄ‚îÄ ui/                     # üñ•Ô∏è Camada de Interface
   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
   ‚îÇ   ‚îú‚îÄ‚îÄ components/        # Componentes reutiliz√°veis
   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chart_builder.py
   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ metric_card.py
   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ session_selector.py
   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ session_state_manager.py
   ‚îÇ   ‚îî‚îÄ‚îÄ pages/             # P√°ginas da aplica√ß√£o
   ‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
   ‚îÇ       ‚îú‚îÄ‚îÄ dashboard.py
   ‚îÇ       ‚îú‚îÄ‚îÄ upload.py
   ‚îÇ       ‚îú‚îÄ‚îÄ analysis.py
   ‚îÇ       ‚îú‚îÄ‚îÄ performance.py
   ‚îÇ       ‚îú‚îÄ‚îÄ consumption.py
   ‚îÇ       ‚îú‚îÄ‚îÄ reports.py
   ‚îÇ       ‚îî‚îÄ‚îÄ imu.py
   ‚îÇ
   ‚îú‚îÄ‚îÄ integration/            # üîó Camada de Integra√ß√£o
   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
   ‚îÇ   ‚îú‚îÄ‚îÄ workflow.py        # Gerenciamento de workflow
   ‚îÇ   ‚îú‚îÄ‚îÄ pipeline.py        # Pipeline de processamento
   ‚îÇ   ‚îú‚îÄ‚îÄ export_import.py   # Import/Export
   ‚îÇ   ‚îú‚îÄ‚îÄ notifications.py   # Sistema de notifica√ß√µes
   ‚îÇ   ‚îú‚îÄ‚îÄ plugins.py         # Sistema de plugins
   ‚îÇ   ‚îú‚îÄ‚îÄ events.py          # Sistema de eventos
   ‚îÇ   ‚îú‚îÄ‚îÄ background.py      # Processamento background
   ‚îÇ   ‚îú‚îÄ‚îÄ clipboard.py       # Integra√ß√£o clipboard
   ‚îÇ   ‚îî‚îÄ‚îÄ integration_manager.py # Gerenciador central
   ‚îÇ
   ‚îî‚îÄ‚îÄ utils/                  # üõ†Ô∏è Utilit√°rios
       ‚îú‚îÄ‚îÄ __init__.py
       ‚îú‚îÄ‚îÄ logger.py          # Sistema de logging
       ‚îî‚îÄ‚îÄ logging_config.py  # Configura√ß√£o de logs

Responsabilidades por Camada
----------------------------

**Data Layer** (src/data/)
   - Parsing e valida√ß√£o de arquivos CSV
   - Modelos de dom√≠nio (TelemetryData, VehicleProfile)
   - Normaliza√ß√£o e limpeza de dados
   - Persist√™ncia e cache
   - Qualidade e integridade dos dados

**Analysis Layer** (src/analysis/)
   - Algoritmos de an√°lise especializados
   - Factory pattern para cria√ß√£o de analisadores
   - C√°lculos de performance e efici√™ncia
   - An√°lises estat√≠sticas e preditivas
   - Gera√ß√£o de relat√≥rios

**UI Layer** (src/ui/)
   - Interface Streamlit
   - Componentes reutiliz√°veis
   - P√°ginas especializadas
   - Gerenciamento de estado da UI
   - Visualiza√ß√µes interativas

**Integration Layer** (src/integration/)
   - Workflows de processamento
   - Import/Export de dados
   - Sistema de plugins e eventos
   - Integra√ß√µes externas
   - Processamento em background

üèõÔ∏è Padr√µes Arquiteturais
========================

Factory Pattern
---------------

Usado para cria√ß√£o de analisadores especializados:

.. code-block:: python

   # src/analysis/analysis.py
   class AnalyzerFactory:
       _analyzers = {
           'performance': PerformanceAnalyzer,
           'statistics': StatisticalAnalyzer,
           'correlation': CorrelationAnalyzer,
           'anomaly': AnomalyDetector,
           'predictive': PredictiveAnalyzer,
       }
       
       @classmethod
       def create_analyzer(cls, analyzer_type: str) -> BaseAnalyzer:
           """Criar analisador espec√≠fico."""
           if analyzer_type not in cls._analyzers:
               raise ValueError(f"Tipo de analisador desconhecido: {analyzer_type}")
           
           return cls._analyzers[analyzer_type]()
       
       @classmethod
       def register_analyzer(cls, name: str, analyzer_class: type):
           """Registrar novo tipo de analisador."""
           cls._analyzers[name] = analyzer_class

Repository Pattern
------------------

Para abstra√ß√£o de persist√™ncia:

.. code-block:: python

   # src/data/database.py
   from abc import ABC, abstractmethod
   
   class SessionRepository(ABC):
       @abstractmethod
       def save_session(self, data: TelemetryData) -> str:
           pass
       
       @abstractmethod
       def load_session(self, session_id: str) -> TelemetryData:
           pass
       
       @abstractmethod
       def find_sessions(self, criteria: dict) -> List[SessionMetadata]:
           pass
   
   class SQLiteSessionRepository(SessionRepository):
       def __init__(self, db_path: str):
           self.db_path = db_path
       
       def save_session(self, data: TelemetryData) -> str:
           # Implementa√ß√£o espec√≠fica SQLite
           pass

Observer Pattern
----------------

Para sistema de eventos e notifica√ß√µes:

.. code-block:: python

   # src/integration/events.py
   from typing import Dict, List, Callable
   
   class EventBus:
       def __init__(self):
           self._observers: Dict[str, List[Callable]] = {}
       
       def subscribe(self, event_type: str, callback: Callable):
           """Inscrever observador para tipo de evento."""
           if event_type not in self._observers:
               self._observers[event_type] = []
           self._observers[event_type].append(callback)
       
       def emit(self, event_type: str, data: dict):
           """Emitir evento para todos os observadores."""
           if event_type in self._observers:
               for callback in self._observers[event_type]:
                   callback(data)

Strategy Pattern
----------------

Para diferentes estrat√©gias de an√°lise e exporta√ß√£o:

.. code-block:: python

   # src/integration/export_import.py
   from abc import ABC, abstractmethod
   
   class ExportStrategy(ABC):
       @abstractmethod
       def export(self, data: TelemetryData, filepath: str):
           pass
   
   class ExcelExportStrategy(ExportStrategy):
       def export(self, data: TelemetryData, filepath: str):
           # Exporta√ß√£o para Excel
           pass
   
   class PDFExportStrategy(ExportStrategy):
       def export(self, data: TelemetryData, filepath: str):
           # Exporta√ß√£o para PDF
           pass
   
   class ExportManager:
       def __init__(self):
           self.strategies = {
               'excel': ExcelExportStrategy(),
               'pdf': PDFExportStrategy(),
               'csv': CSVExportStrategy()
           }
       
       def export(self, format_type: str, data: TelemetryData, filepath: str):
           strategy = self.strategies.get(format_type)
           if not strategy:
               raise ValueError(f"Formato n√£o suportado: {format_type}")
           return strategy.export(data, filepath)

üîÑ Fluxo de Dados
================

Pipeline Principal
------------------

.. mermaid::

   flowchart TD
       UPLOAD[üìÅ Upload CSV] --> PARSE[üîç Parse & Validate]
       PARSE --> NORMALIZE[‚öôÔ∏è Normalize Data]
       NORMALIZE --> CACHE[üíæ Cache Data]
       CACHE --> ANALYZE[üî¨ Run Analysis]
       ANALYZE --> VISUALIZE[üìä Generate Charts]
       VISUALIZE --> EXPORT[üìÑ Export Results]
       
       PARSE -.-> ERRORS[‚ùå Handle Errors]
       NORMALIZE -.-> CLEAN[üßπ Data Cleaning]
       ANALYZE -.-> BACKGROUND[‚ö° Background Tasks]

Fluxo Detalhado de Processamento
--------------------------------

.. code-block:: python

   # Fluxo t√≠pico de processamento
   def process_telemetry_file(filepath: str) -> ProcessingResult:
       """Pipeline completo de processamento."""
       
       # 1. Parsing e valida√ß√£o inicial
       parser = CSVParserFactory.create_parser(filepath)
       raw_data = parser.parse(filepath)
       
       # 2. Valida√ß√£o de dados
       validator = DataValidator()
       validation_result = validator.validate(raw_data)
       
       if not validation_result.is_valid:
           return ProcessingResult.error(validation_result.errors)
       
       # 3. Normaliza√ß√£o e limpeza
       normalizer = DataNormalizer()
       clean_data = normalizer.normalize(raw_data)
       
       # 4. Cria√ß√£o do modelo de dom√≠nio
       telemetry_data = TelemetryData.from_dataframe(clean_data)
       
       # 5. Cache dos dados processados
       cache_manager = CacheManager()
       data_hash = cache_manager.store(telemetry_data)
       
       # 6. An√°lises autom√°ticas
       analysis_results = {}
       for analysis_type in ['performance', 'statistics', 'anomaly']:
           analyzer = AnalyzerFactory.create_analyzer(analysis_type)
           analysis_results[analysis_type] = analyzer.analyze(telemetry_data)
       
       # 7. Notifica√ß√£o de conclus√£o
       event_bus = EventBus()
       event_bus.emit('processing_completed', {
           'data_hash': data_hash,
           'analysis_results': analysis_results
       })
       
       return ProcessingResult.success(telemetry_data, analysis_results)

Estado da Aplica√ß√£o
-------------------

Gerenciamento de estado usando Streamlit Session State:

.. code-block:: python

   # src/ui/components/session_state_manager.py
   import streamlit as st
   from typing import Optional, Any
   
   class SessionStateManager:
       """Gerenciador centralizado do estado da sess√£o."""
       
       @staticmethod
       def get_current_data() -> Optional[TelemetryData]:
           """Obter dados atuais da sess√£o."""
           return st.session_state.get('current_telemetry_data')
       
       @staticmethod
       def set_current_data(data: TelemetryData):
           """Definir dados atuais da sess√£o."""
           st.session_state['current_telemetry_data'] = data
           st.session_state['data_loaded'] = True
           st.session_state['last_update'] = datetime.now()
       
       @staticmethod
       def get_analysis_results(analysis_type: str) -> Optional[dict]:
           """Obter resultados de an√°lise espec√≠fica."""
           results = st.session_state.get('analysis_results', {})
           return results.get(analysis_type)
       
       @staticmethod
       def set_analysis_results(analysis_type: str, results: dict):
           """Armazenar resultados de an√°lise."""
           if 'analysis_results' not in st.session_state:
               st.session_state['analysis_results'] = {}
           st.session_state['analysis_results'][analysis_type] = results

üé® Padr√µes de Design de Interface
================================

Component-Based Architecture
----------------------------

Interface constru√≠da com componentes reutiliz√°veis:

.. code-block:: python

   # src/ui/components/metric_card.py
   import streamlit as st
   from typing import Optional
   
   class MetricCard:
       """Componente reutiliz√°vel para exibir m√©tricas."""
       
       @staticmethod
       def render(
           title: str,
           value: str,
           delta: Optional[str] = None,
           help_text: Optional[str] = None
       ):
           """Renderizar card de m√©trica."""
           col1, col2 = st.columns([3, 1])
           
           with col1:
               st.metric(
                   label=title,
                   value=value,
                   delta=delta,
                   help=help_text
               )
           
           with col2:
               if help_text:
                   st.info(help_text)

Page Pattern
------------

Cada p√°gina √© uma classe com responsabilidades espec√≠ficas:

.. code-block:: python

   # src/ui/pages/dashboard.py
   import streamlit as st
   from abc import ABC, abstractmethod
   
   class BasePage(ABC):
       """Classe base para todas as p√°ginas."""
       
       def __init__(self, title: str):
           self.title = title
       
       def render(self):
           """Renderizar p√°gina completa."""
           st.title(self.title)
           self.render_sidebar()
           self.render_content()
       
       @abstractmethod
       def render_content(self):
           """Renderizar conte√∫do espec√≠fico da p√°gina."""
           pass
       
       def render_sidebar(self):
           """Renderizar sidebar (pode ser sobrescrito)."""
           pass
   
   class DashboardPage(BasePage):
       def __init__(self):
           super().__init__("üìä Dashboard")
       
       def render_content(self):
           data = SessionStateManager.get_current_data()
           if not data:
               st.warning("Nenhum dado carregado. Fa√ßa upload de um arquivo.")
               return
           
           self.render_metrics(data)
           self.render_charts(data)
       
       def render_metrics(self, data: TelemetryData):
           # Renderizar m√©tricas principais
           pass
       
       def render_charts(self, data: TelemetryData):
           # Renderizar gr√°ficos
           pass

üîß Sistema de Configura√ß√£o
==========================

Configura√ß√£o Hier√°rquica
------------------------

.. code-block:: python

   # config.py
   from dataclasses import dataclass
   from typing import Optional
   import os
   
   @dataclass
   class DatabaseConfig:
       url: str = "sqlite:///fueltune.db"
       echo: bool = False
       pool_size: int = 5
   
   @dataclass
   class CacheConfig:
       enabled: bool = True
       ttl: int = 3600  # 1 hora
       max_size_mb: int = 500
   
   @dataclass
   class AnalysisConfig:
       auto_analysis: bool = True
       default_types: list = None
       parallel_processing: bool = True
       max_workers: int = 4
       
       def __post_init__(self):
           if self.default_types is None:
               self.default_types = ['performance', 'statistics', 'anomaly']
   
   @dataclass
   class AppConfig:
       debug: bool = False
       log_level: str = "INFO"
       database: DatabaseConfig = DatabaseConfig()
       cache: CacheConfig = CacheConfig()
       analysis: AnalysisConfig = AnalysisConfig()
       
       @classmethod
       def from_env(cls) -> 'AppConfig':
           """Criar configura√ß√£o a partir de vari√°veis de ambiente."""
           return cls(
               debug=os.getenv('DEBUG', 'false').lower() == 'true',
               log_level=os.getenv('LOG_LEVEL', 'INFO'),
               database=DatabaseConfig(
                   url=os.getenv('DATABASE_URL', 'sqlite:///fueltune.db')
               ),
               cache=CacheConfig(
                   enabled=os.getenv('CACHE_ENABLED', 'true').lower() == 'true',
                   ttl=int(os.getenv('CACHE_TTL', '3600'))
               )
           )

Inje√ß√£o de Depend√™ncias
-----------------------

.. code-block:: python

   # src/utils/container.py
   from typing import Dict, Any, TypeVar, Type
   
   T = TypeVar('T')
   
   class Container:
       """Container de inje√ß√£o de depend√™ncias."""
       
       def __init__(self):
           self._services: Dict[str, Any] = {}
           self._singletons: Dict[str, Any] = {}
       
       def register(self, interface: Type[T], implementation: Type[T], singleton: bool = True):
           """Registrar implementa√ß√£o para interface."""
           key = interface.__name__
           self._services[key] = implementation
           if singleton and key not in self._singletons:
               self._singletons[key] = implementation()
       
       def resolve(self, interface: Type[T]) -> T:
           """Resolver implementa√ß√£o para interface."""
           key = interface.__name__
           
           if key in self._singletons:
               return self._singletons[key]
           
           if key in self._services:
               return self._services[key]()
           
           raise ValueError(f"Servi√ßo n√£o registrado: {key}")

üìä Monitoramento e Observabilidade
==================================

Sistema de Logging
------------------

.. code-block:: python

   # src/utils/logging_config.py
   import logging
   import sys
   from pathlib import Path
   
   def setup_logging(log_level: str = "INFO", log_dir: Path = Path("logs")):
       """Configurar sistema de logging."""
       
       # Criar diret√≥rio de logs
       log_dir.mkdir(exist_ok=True)
       
       # Configurar formatters
       formatter = logging.Formatter(
           '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
       )
       
       # Logger principal
       logger = logging.getLogger('fueltune')
       logger.setLevel(getattr(logging, log_level.upper()))
       
       # Handler para arquivo
       file_handler = logging.FileHandler(log_dir / 'fueltune.log')
       file_handler.setFormatter(formatter)
       logger.addHandler(file_handler)
       
       # Handler para console
       console_handler = logging.StreamHandler(sys.stdout)
       console_handler.setFormatter(formatter)
       logger.addHandler(console_handler)
       
       # Logger espec√≠fico para erros
       error_logger = logging.getLogger('fueltune.errors')
       error_handler = logging.FileHandler(log_dir / 'errors.log')
       error_handler.setFormatter(formatter)
       error_handler.setLevel(logging.ERROR)
       error_logger.addHandler(error_handler)

M√©tricas de Performance
----------------------

.. code-block:: python

   # src/utils/metrics.py
   import time
   import functools
   from typing import Dict, Any
   
   class PerformanceMetrics:
       """Coletor de m√©tricas de performance."""
       
       def __init__(self):
           self.metrics: Dict[str, Any] = {}
       
       def time_function(self, func_name: str):
           """Decorator para medir tempo de execu√ß√£o."""
           def decorator(func):
               @functools.wraps(func)
               def wrapper(*args, **kwargs):
                   start_time = time.time()
                   result = func(*args, **kwargs)
                   end_time = time.time()
                   
                   execution_time = end_time - start_time
                   self.record_metric(f"{func_name}_execution_time", execution_time)
                   
                   return result
               return wrapper
           return decorator
       
       def record_metric(self, name: str, value: Any):
           """Registrar m√©trica."""
           if name not in self.metrics:
               self.metrics[name] = []
           self.metrics[name].append({
               'value': value,
               'timestamp': time.time()
           })

üîê Seguran√ßa e Valida√ß√£o
=======================

Valida√ß√£o de Entrada
--------------------

.. code-block:: python

   # src/data/validators.py
   import pandera as pa
   from pandera import DataFrameSchema, Column, Check
   
   class SecurityValidator:
       """Validador de seguran√ßa para entrada de dados."""
       
       @staticmethod
       def validate_file_upload(file_content: bytes, max_size_mb: int = 100) -> bool:
           """Validar arquivo de upload."""
           
           # Verificar tamanho
           if len(file_content) > max_size_mb * 1024 * 1024:
               raise ValueError(f"Arquivo muito grande (max {max_size_mb}MB)")
           
           # Verificar conte√∫do malicioso
           suspicious_patterns = [b'<script', b'javascript:', b'<?php']
           for pattern in suspicious_patterns:
               if pattern in file_content.lower():
                   raise ValueError("Conte√∫do suspeito detectado")
           
           return True
       
       @staticmethod
       def sanitize_filename(filename: str) -> str:
           """Sanitizar nome do arquivo."""
           import re
           # Remove caracteres perigosos
           safe_filename = re.sub(r'[^a-zA-Z0-9._-]', '_', filename)
           return safe_filename[:100]  # Limitar tamanho

Controle de Acesso
------------------

.. code-block:: python

   # src/utils/auth.py
   from enum import Enum
   from typing import Set
   
   class Permission(Enum):
       READ_DATA = "read_data"
       WRITE_DATA = "write_data"
       EXPORT_DATA = "export_data"
       ADMIN_ACCESS = "admin_access"
   
   class User:
       def __init__(self, username: str, permissions: Set[Permission]):
           self.username = username
           self.permissions = permissions
       
       def has_permission(self, permission: Permission) -> bool:
           return permission in self.permissions

üìà Escalabilidade e Performance
==============================

Processamento Paralelo
----------------------

.. code-block:: python

   # src/analysis/parallel.py
   from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
   from typing import List, Callable, Any
   
   class ParallelProcessor:
       """Processador paralelo para an√°lises."""
       
       def __init__(self, max_workers: int = 4):
           self.max_workers = max_workers
       
       def process_parallel(
           self, 
           tasks: List[Callable],
           use_processes: bool = False
       ) -> List[Any]:
           """Processar tarefas em paralelo."""
           
           executor_class = ProcessPoolExecutor if use_processes else ThreadPoolExecutor
           
           with executor_class(max_workers=self.max_workers) as executor:
               futures = [executor.submit(task) for task in tasks]
               results = [future.result() for future in futures]
           
           return results

Cache Distribu√≠do
-----------------

.. code-block:: python

   # src/data/cache.py
   import redis
   import pickle
   from typing import Optional, Any
   
   class DistributedCache:
       """Cache distribu√≠do usando Redis."""
       
       def __init__(self, redis_url: str = "redis://localhost:6379"):
           self.client = redis.from_url(redis_url)
       
       def get(self, key: str) -> Optional[Any]:
           """Obter valor do cache."""
           data = self.client.get(key)
           if data:
               return pickle.loads(data)
           return None
       
       def set(self, key: str, value: Any, ttl: int = 3600):
           """Armazenar valor no cache."""
           data = pickle.dumps(value)
           self.client.setex(key, ttl, data)

üß™ Testabilidade
===============

Arquitetura Orientada a Testes
------------------------------

.. code-block:: python

   # tests/unit/test_analysis.py
   import pytest
   from unittest.mock import Mock, patch
   from src.analysis.performance import PerformanceAnalyzer
   
   class TestPerformanceAnalyzer:
       """Testes para analisador de performance."""
       
       def setup_method(self):
           """Configurar cada teste."""
           self.analyzer = PerformanceAnalyzer()
           self.mock_data = self.create_mock_telemetry_data()
       
       def create_mock_telemetry_data(self):
           """Criar dados mock para testes."""
           # Implementar cria√ß√£o de dados de teste
           pass
       
       def test_calculate_max_power(self):
           """Testar c√°lculo de pot√™ncia m√°xima."""
           result = self.analyzer.calculate_max_power(self.mock_data)
           assert result > 0
           assert isinstance(result, float)
       
       @patch('src.data.cache.CacheManager')
       def test_analysis_with_cache(self, mock_cache):
           """Testar an√°lise com cache mockado."""
           mock_cache.return_value.get.return_value = None
           result = self.analyzer.analyze(self.mock_data)
           assert result is not None
           mock_cache.return_value.set.assert_called_once()

Integration Testing
-------------------

.. code-block:: python

   # tests/integration/test_full_pipeline.py
   import pytest
   from pathlib import Path
   from src.data.csv_parser import parse_fueltech_csv
   from src.analysis import AnalyzerFactory
   
   class TestFullPipeline:
       """Testes de integra√ß√£o do pipeline completo."""
       
       def test_complete_workflow(self):
           """Testar workflow completo do upload √† an√°lise."""
           
           # Carregar dados de teste
           test_file = Path("tests/fixtures/sample_data.csv")
           data = parse_fueltech_csv(str(test_file))
           
           # Executar an√°lises
           analyzer = AnalyzerFactory.create_analyzer("performance")
           results = analyzer.analyze(data)
           
           # Verificar resultados
           assert 'max_power' in results
           assert results['max_power'] > 0

üìö Documenta√ß√£o da Arquitetura
==============================

ADRs (Architecture Decision Records)
------------------------------------

Decis√µes arquiteturais importantes s√£o documentadas como ADRs:

.. code-block:: markdown

   # ADR-001: Escolha do Streamlit como Framework de UI
   
   ## Status
   Aceito
   
   ## Contexto
   Necessitamos de um framework para criar interface web interativa
   para an√°lise de dados, com foco em prototipagem r√°pida.
   
   ## Decis√£o
   Usar Streamlit como framework principal de UI.
   
   ## Consequ√™ncias
   - **Positivas**: Desenvolvimento r√°pido, integra√ß√£o com pandas/plotly
   - **Negativas**: Limita√ß√µes de customiza√ß√£o, single-threaded

Diagramas C4
------------

Documenta√ß√£o visual usando diagramas C4:

.. mermaid::

   C4Context
       title System Context Diagram for FuelTune Analyzer
       
       Person(user, "Engine Tuner", "Professional who analyzes telemetry data")
       System(fueltune, "FuelTune Analyzer", "Analyzes FuelTech telemetry data")
       System_Ext(fueltech, "FuelTech ECU", "Generates telemetry CSV files")
       System_Ext(dyno, "Dynamometer", "Provides additional performance data")
       
       Rel(user, fueltune, "Uses")
       Rel(fueltune, fueltech, "Imports data from")
       Rel(fueltune, dyno, "Correlates with")

üîÑ Evolu√ß√£o da Arquitetura
==========================

Roadmap Arquitetural
--------------------

**Vers√£o 2.1 (Q1 2025)**
   - Microservices para an√°lises pesadas
   - API REST completa
   - Cache distribu√≠do

**Vers√£o 2.2 (Q2 2025)**
   - Sistema de plugins extens√≠vel
   - Processamento real-time
   - Machine Learning pipeline

**Vers√£o 3.0 (Q4 2025)**
   - Arquitetura cloud-native
   - Multi-tenancy
   - Auto-scaling

Refatora√ß√µes Planejadas
----------------------

1. **Extra√ß√£o de Domain Models**
   - Separar l√≥gica de neg√≥cio dos DTOs
   - Implementar rich domain models

2. **Event-Driven Architecture**
   - Migrar para arquitetura baseada em eventos
   - Implementar CQRS para queries complexas

3. **Modulariza√ß√£o**
   - Extrair an√°lises para m√≥dulos independentes
   - Plugin system para extens√µes customizadas

----

Esta arquitetura fornece uma base s√≥lida e extens√≠vel para o FuelTune Analyzer, 
balanceando simplicidade, performance e facilidade de manuten√ß√£o. 

Para contribuir com melhorias arquiteturais, consulte o :doc:`contributing`.